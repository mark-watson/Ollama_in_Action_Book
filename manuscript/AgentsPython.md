# Using AG2 Open-Source AgentOS LLM-Based Agent Framework for Generating and Executing Python Code

AG2 Open-Source AgentOS is a fork of Microsoft’s Autogen agent framework by many or the original creators. While I am a fan of Autogen, I find AG2 simpler to work with when using local models on my laptop and we will use the forked library here.

The AG2 agent framework is an excellent tool for creating multi-agent applications, though it was originally designed to work primarily with OpenAI’s models. In this chapter, we demonstrate how to use its capabilities with a local Ollama model (qwen2.5:14b.) We use a modified version of an AG2 example that combines Python and Matplotlib with AG2, showcasing how local deployment can be achieved without sacrificing the robust tool calling features the framework offers.

This approach provides several benefits. By leveraging a local model via Ollama, developers reduce dependency on external APIs, enhance privacy and security, and potentially lower operational costs while retaining the power of AG2’s code generation and execution. The example illustrates how an assistant agent generates the necessary code to perform tasks, and a user proxy agent executes that code to produce dynamic visualizations, such as plotting stock price changes. This decoupling of code generation from execution not only enhances reliability but also allows for greater customization of the execution environment. 

## Example Implementation

I experimented with several local models using Ollama with mediocre results but the larger **qwen2.5:14b** model works very well. If you are running on a Mac you will need an Apple Silicon chip with 16G of memory to run this model.

```python
from autogen import AssistantAgent, UserProxyAgent

# Requirements:
# pip install ag2 ollama fix_busted_json yfinance matplotlib

config_list = [
 {
    "model": "qwen2.5:14b",   # Choose a model that supports tool calling
    "api_type": "ollama",     # Specify Ollama as the API type
    "client_host": "http://localhost:11434",  # local Ollama server
    "api_key": "fakekey",
    "native_tool_calls": True # Enable native tool calling 
 }
]

# Create the AssistantAgent using the local model config
assistant = AssistantAgent("assistant",
                           llm_config={"config_list": config_list})

# Create the UserProxyAgent; adjust code_execution_config as needed.
user_proxy = UserProxyAgent(
    "user_proxy",
    code_execution_config={"work_dir": "coding", "use_docker": False}
)

# Initiate an automated chat between the agents.
user_proxy.initiate_chat(
    assistant,
    message="Plot a chart of NVDA and TESLA stock price change YTD."
)
```

This code sets up a multi-agent workflow using AG2 by configuring an assistant agent and a user proxy agent. First, it defines a configuration for a local Ollama-based model (here, "qwen2.5:14b") that supports native tool calling. The configuration specifies details such as the API type ("ollama"), the local server URL ("http://localhost:11434"), a placeholder API key, and an option to enable native tool calls. This configuration is then passed to instantiate the AssistantAgent, which uses it to generate responses based on the local LLM.

This example uses a UserProxyAgent configured for Python code execution with a designated working directory ("coding") and Docker disabled. Finally, the user proxy agent initiates an automated chat with the assistant by sending a message requesting the plotting of a chart for NVDA and TESLA stock price changes year-to-date. This setup demonstrates a simple, automated multi-agent interaction where the assistant generates responses (potentially including code) and the user proxy executes those responses to fulfill the requested task. You will either want to remove the generated code directory **coding** after running this example of add **coding** to your **.gitignore** file.

We use **uv** to run Python examples in this book. Internally the AG2 agent library will write, install dependencies in a sandbox, and run automatically generated code. Therefore, we must explicitly install *pip** inside the directory local **uv** **.venv** environment:

```
uv venv
uv pip install pip
uv run autogen_python_example.py
```

The agent will generate Python code that it tries to run in a sandbox. As mentioned, **pip** is required for that to pull in libraries for the generated Python code.

## Example Output

![Plot generated by Matplotlib run by agent](images/autogen1.jpg)

Here is a partial listing of the output:

```text
$ uv venv
$ uv pip install pip
$ uv run autogen_python_example.py  

user_proxy (to assistant):

Plot a chart of NVDA and TESLA stock price change YTD.

-------------------------------------------------------------
assistant (to user_proxy):

To plot a chart of NVDA (NVIDIA) and Tesla's stock price changes year-to-date, we will need to fetch their historical data from an API or a financial data source such as Yahoo Finance.

Let's use Python with the `yfinance` library to get the data and then plot it using `matplotlib`.

Here is a step-by-step plan:

1. **Install Required Libraries**: If not already installed, install `yfinance` for fetching stock data and `pandas` & `matplotlib` for processing and plotting the data.
2. **Fetch Stock Data**: Use `yfinance` to get the year-to-date historical data for NVDA and TSLA stocks.
3. **Plot Data**: Plot the closing prices of both stocks on a chart.

Let's start by fetching and plotting the stock price data with Python code:

``python
# filename: plot_stock_prices.py

import yfinance as yf
import matplotlib.pyplot as plt
import pandas as pd

# Fetch year-to-date historical data for NVDA and TSLA
stocks = ['NVDA', 'TSLA']
data = yf.download(stocks, start='2023-01-01')['Close']

# Plot the closing prices of both stocks
plt.figure(figsize=(14,7))
for stock in stocks:
    plt.plot(data.index, data[stock], label=stock)
    
plt.title('Year-to-date Stock Prices for NVDA and TSLA')
plt.xlabel('Date')
plt.ylabel('Stock Price (USD)')
plt.legend()
plt.grid(True)
plt.show()
``

You can execute the above Python script to generate the plot. Please make sure you have `yfinance`, `matplotlib`, and `pandas` installed in your environment. If not, install them by running:

``sh
pip install yfinance matplotlib pandas
``

After executing the code, you should see a chart showing the year-to-date closing prices for both NVDA and TSLA stocks.

Once you have executed this script, please inform me of any issues or if everything is plotted correctly.

-------------------------------------------------------------
Replying as user_proxy. Provide feedback to assistant. Press enter to skip and use auto-reply, or type 'exit' to end the conversation:

>>>>>>>> NO HUMAN INPUT RECEIVED.
>>>>>>>> USING AUTO REPLY...
>>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...
```

## Wrap Up for Using AG2’s Agent Framework for Generating and Executing Python Code

Here we experimented with using Ollama and a local model to use the powerful AG2 agent framework.

The AG2 framework for Python tool calling agents streamlines the development of multi-agent applications by enabling seamless interaction between an assistant agent and a user proxy agent. In the example, we configured a local LLM (using a model like “qwen2.5:14b” via Ollama) and instantiated an AssistantAgent to generate responses and code, while a UserProxyAgent was set up to execute the generated code. This automated conversation allowed the agents to collaborate on a task—plotting a chart for NVDA and TESLA stock price changes year-to-date—demonstrating how AG2 bridges code generation and execution in an autonomous workflow.   ￼

This example highlights AG2’s ability to leverage native tool calling within a Python environment, reducing the need for manual intervention during code execution and debugging. By decoupling the generation of task-specific code from its execution, developers can build systems that are both flexible and scalable. The assistant agent focuses on planning and generating code, while the user proxy agent reliably executes that code, creating an effective feedback loop for refining results. This pattern not only simplifies complex workflows but also provides a foundation for robust, error-resilient applications.

To further explore the potential of AG2, you dear reader might experiment with integrating additional tools—such as web scraping modules, database connectors, or advanced visualization libraries—to expand the capabilities of their agents. Another interesting avenue is to adjust the configuration parameters: try different LLM models, enable Docker-based code execution, or incorporate human-in-the-loop feedback to refine responses. Additionally, extending the workflow to include more specialized agents (e.g., a dedicated CodeExecutorAgent or a DebuggingAgent) can provide insights into multi-agent orchestration and the scalability of autonomous systems. These experiments will help readers understand the full versatility of AG2 in creating dynamic, multi-step applications.
